<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>爬虫题库 | Besos的博客</title>
  <meta name="baidu-site-verification" content="LMxJyO5q7Y" />
  <meta name="keywords" content=" 爬虫 ">
  <meta name="description" content="爬虫题库 | Besos的博客">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="个人简介堵俊杰， 毕业于郑大，目前从事 Python 及相关工作。 喜欢研究新兴技术和未来发展方向。 最近在彭小六的六扇门内，研习阅读方法、知识管理、时间管理等方法。 联系方式 QQ : 784577996 邮箱 :  dujunjie666@gmail.com">
<meta property="og:type" content="website">
<meta property="og:title" content="关于&amp;留言板">
<meta property="og:url" content="http://yoursite.com/about/index.html">
<meta property="og:site_name" content="Besos的博客">
<meta property="og:description" content="个人简介堵俊杰， 毕业于郑大，目前从事 Python 及相关工作。 喜欢研究新兴技术和未来发展方向。 最近在彭小六的六扇门内，研习阅读方法、知识管理、时间管理等方法。 联系方式 QQ : 784577996 邮箱 :  dujunjie666@gmail.com">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-01-14T06:27:45.000Z">
<meta property="article:modified_time" content="2020-01-14T06:54:13.445Z">
<meta property="article:author" content="Besos的博客">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.0.1" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.0.1" rel="stylesheet">

<link href="//cdn.bootcss.com/animate.css/3.5.2/animate.min.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="/js/jquery.autocomplete.min.js?v=1.0.1" ></script>

<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>



<script src="//cdn.bootcss.com/jquery-cookie/1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.0.1" ></script>

	<script src="/live2d/autoload.js"></script>
<meta name="generator" content="Hexo 4.2.0"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="false">
  <input class="theme_blog_path" value="">
</div>
<script src="/js/aixin.js"></script>
<iframe src="https://zhanyuzhang.github.io/lovely-cat/cat.html" frameborder="0" id="catIframe"></iframe>

<style>

#catIframe {
position: fixed;
width: 400px;
/* padding: 50px 0px; */
top: 70%;
left: 95%;
transform: translate(-68%, -50%);
}
</style>

<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/avatar.jpg" />
</a>
<div class="author">
    <span>Besos的博客</span>
</div>

<div class="icon">
    
        
        <a title="rss" href="/atom.xml" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-rss"></use>
                </svg>
            
        </a>
        
    
        
        <a title="github" href="https://github.com/yelog" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-github"></use>
                </svg>
            
        </a>
        
    
        
        <a title="facebook" href="https://www.facebook.com/faker.tops" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-facebook"></use>
                </svg>
            
        </a>
        
    
        
    
        
    
        
        <a title="instagram" href="https://www.facebook.com/faker.tops" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-instagram"></use>
                </svg>
            
        </a>
        
    
        
        <a title="reddit" href="https://www.reddit.com/user/yelog/" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-reddit"></use>
                </svg>
            
        </a>
        
    
        
        <a title="weibo" href="http://weibo.com/u/2307534817" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-weibo"></use>
                </svg>
            
        </a>
        
    
        
        <a title="jianshu" href="https://www.jianshu.com/u/ff56736de7cf" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-jianshu"></use>
                </svg>
            
        </a>
        
    
        
        <a title="zhihu" href="https://www.zhihu.com/people/jaytp/activities" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-zhihu"></use>
                </svg>
            
        </a>
        
    
        
    
        
        <a title="oschina" href="https://my.oschina.net/yelog" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-oschina"></use>
                </svg>
            
        </a>
        
    
        
    
        
        <a title="email" href="mailto:jaytp@qq.com" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-email"></use>
                </svg>
            
        </a>
        
    
        
        <a title="qq" href="http://wpa.qq.com/msgrd?v=3&uin=872336115&site=qq&menu=yes" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-qq"></use>
                </svg>
            
        </a>
        
    
        
        <a title="kugou" href="https://www.kugou.com/" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-kugou"></use>
                </svg>
            
        </a>
        
    
        
        <a title="neteasemusic" href="https://music.163.com/#/user/home?id=88151013" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-neteasemusic"></use>
                </svg>
            
        </a>
        
    
</div>




<ul>
    <li><div class="all active">全部文章<small>(32)</small></div></li>
    
        
            
            <li><div data-rel="python">python<small>(9)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="数据库">数据库<small>(6)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="运维">运维<small>(11)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="小实训">小实训<small>(6)</small></div>
                
            </li>
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    
    
    </div>
    <div><a class="about  hasFriend  site_url"  href="/about">关于</a><a style="width: 50%"  class="friends">友链</a></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="32">
<input type="hidden" id="yelog_site_word_count" value="23.3k">
<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="back-title-list"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://zfblog.xyz/">陈士方</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <form onkeydown="if(event.keyCode==13){return false;}">
        <input class="search" type="text" placeholder="Search..." autocomplete="off"id="local-search-input" >
        <i class="cross"></i>
        <span>
            <label for="tagswitch">Tags:</label>
            <input id="tagswitch" type="checkbox" style="display: none" />
            <i id="tagsWitchIcon"></i>
        </span>
    </form>
    <div class="tags-list">
    
    <li class="article-tag-list-item">
        <a class="color2">python</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">文件</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">爬虫</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">命令</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">PostgreSQL</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">git</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">hugo</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">vue</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">django</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">docker</a>
    </li>
    
    <div class="clearfix"></div>
</div>

    
    <nav id="title-list-nav">
        
        <a  class="python "
           href="/2019/12/24/%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%A8%A1%E5%9D%97/"
           data-tag="python"
           data-author="" >
            <span class="post-title" title="随机数模块">随机数模块</span>
            <span class="post-date" title="2019-12-24 08:48:12">2019/12/24</span>
        </a>
        
        <a  class="python "
           href="/2019/12/24/%E6%97%B6%E9%97%B4%E6%A8%A1%E5%9D%97/"
           data-tag="python"
           data-author="" >
            <span class="post-title" title="时间模块">时间模块</span>
            <span class="post-date" title="2019-12-24 08:50:49">2019/12/24</span>
        </a>
        
        <a  class="python "
           href="/2019/12/23/os%E6%A8%A1%E5%9D%97/"
           data-tag="文件"
           data-author="" >
            <span class="post-title" title="os模块">os模块</span>
            <span class="post-date" title="2019-12-23 16:05:53">2019/12/23</span>
        </a>
        
        <a  class="python "
           href="/2019/12/25/%E7%AE%80%E6%98%93%E7%99%BE%E5%BA%A6%E5%9B%BE%E7%89%87%E7%88%AC%E8%99%AB/"
           data-tag="爬虫"
           data-author="" >
            <span class="post-title" title="简易百度图片爬虫">简易百度图片爬虫</span>
            <span class="post-date" title="2019-12-25 08:00:00">2019/12/25</span>
        </a>
        
        <a  class="python "
           href="/2019/12/26/%E6%AD%A3%E5%88%99/"
           data-tag="python"
           data-author="" >
            <span class="post-title" title="正则">正则</span>
            <span class="post-date" title="2019-12-26 08:43:12">2019/12/26</span>
        </a>
        
        <a  class="python "
           href="/2019/12/27/%E8%A3%85%E9%A5%B0%E5%99%A8%E5%87%BD%E6%95%B0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="装饰器函数">装饰器函数</span>
            <span class="post-date" title="2019-12-27 15:48:51">2019/12/27</span>
        </a>
        
        <a  class="运维 "
           href="/2019/12/29/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(3)%20pwd/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令(3) pwd">每天一个linux命令(3) pwd</span>
            <span class="post-date" title="2019-12-29 19:13:03">2019/12/29</span>
        </a>
        
        <a  class="python "
           href="/2019/12/30/%E5%87%BD%E6%95%B0%E9%97%AD%E5%8C%85/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="函数闭包">函数闭包</span>
            <span class="post-date" title="2019-12-30 10:39:01">2019/12/30</span>
        </a>
        
        <a  class="python "
           href="/2019/12/31/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="异常处理">异常处理</span>
            <span class="post-date" title="2019-12-31 09:13:57">2019/12/31</span>
        </a>
        
        <a  class="运维 "
           href="/2019/12/30/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(4)%20mkdir/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令(4) mkdir">每天一个linux命令(4) mkdir</span>
            <span class="post-date" title="2019-12-30 10:35:01">2019/12/30</span>
        </a>
        
        <a  class="运维 "
           href="/2019/12/27/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(2)%20cd/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令(2) cd">每天一个linux命令(2) cd</span>
            <span class="post-date" title="2019-12-27 15:44:58">2019/12/27</span>
        </a>
        
        <a  class="运维 "
           href="/2019/12/26/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(1)%20ls/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令(1) ls">每天一个linux命令(1) ls</span>
            <span class="post-date" title="2019-12-26 19:32:45">2019/12/26</span>
        </a>
        
        <a  class="运维 "
           href="/2019/12/31/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(5)%20rm/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令(5) rm">每天一个linux命令(5) rm</span>
            <span class="post-date" title="2019-12-31 09:10:35">2019/12/31</span>
        </a>
        
        <a  class="python "
           href="/2020/01/09/%E7%88%AC%E8%99%AB%E9%A2%98%E5%BA%93/"
           data-tag="爬虫"
           data-author="" >
            <span class="post-title" title="爬虫题库">爬虫题库</span>
            <span class="post-date" title="2020-01-09 08:48:19">2020/01/09</span>
        </a>
        
        <a  class="运维 "
           href="/2020/01/10/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(6)%20rmdir/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令(6) rmdir">每天一个linux命令(6) rmdir</span>
            <span class="post-date" title="2020-01-10 14:58:50">2020/01/10</span>
        </a>
        
        <a  class="数据库 "
           href="/2020/01/12/PostgreSQL%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%89%E8%A3%85/"
           data-tag="PostgreSQL"
           data-author="" >
            <span class="post-title" title="PostgreSQL的介绍与安装">PostgreSQL的介绍与安装</span>
            <span class="post-date" title="2020-01-12 19:05:13">2020/01/12</span>
        </a>
        
        <a  class="运维 "
           href="/2020/01/12/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(7)%20mv/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令(7) mv">每天一个linux命令(7) mv</span>
            <span class="post-date" title="2020-01-12 18:59:45">2020/01/12</span>
        </a>
        
        <a  class="数据库 "
           href="/2020/01/14/PostgreSQL%E5%88%9D%E4%BD%93%E9%AA%8C/"
           data-tag="PostgreSQL"
           data-author="" >
            <span class="post-title" title="PostgreSQL初体验">PostgreSQL初体验</span>
            <span class="post-date" title="2020-01-14 19:41:52">2020/01/14</span>
        </a>
        
        <a  class="运维 "
           href="/2020/01/16/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(8)%20cp/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令(8) cp">每天一个linux命令(8) cp</span>
            <span class="post-date" title="2020-01-16 17:52:13">2020/01/16</span>
        </a>
        
        <a  class="数据库 "
           href="/2020/01/18/PostgreSQL%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"
           data-tag="PostgreSQL"
           data-author="" >
            <span class="post-title" title="PostgreSQL常用操作">PostgreSQL常用操作</span>
            <span class="post-date" title="2020-01-18 18:41:39">2020/01/18</span>
        </a>
        
        <a  class="运维 "
           href="/2020/02/07/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(9)%20touch/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令(9) touch">每天一个linux命令(9) touch</span>
            <span class="post-date" title="2020-02-07 15:25:37">2020/02/07</span>
        </a>
        
        <a  class="数据库 "
           href="/2020/02/11/PostgreSQL%E5%B8%B8%E7%94%A8SQL%E6%93%8D%E4%BD%9C/"
           data-tag="PostgreSQL"
           data-author="" >
            <span class="post-title" title="PostgreSQL常用SQL操作">PostgreSQL常用SQL操作</span>
            <span class="post-date" title="2020-02-11 16:31:58">2020/02/11</span>
        </a>
        
        <a  class="运维 "
           href="/2020/02/11/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(10)%20cat/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令（10）: cat">每天一个linux命令（10）: cat</span>
            <span class="post-date" title="2020-02-11 16:34:53">2020/02/11</span>
        </a>
        
        <a  class="运维 "
           href="/2020/04/03/%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AAlinux%E5%91%BD%E4%BB%A4(11)%20nl/"
           data-tag="命令"
           data-author="" >
            <span class="post-title" title="每天一个linux命令（11）: nl">每天一个linux命令（11）: nl</span>
            <span class="post-date" title="2020-04-03 15:40:47">2020/04/03</span>
        </a>
        
        <a  class="小实训 "
           href="/2020/04/20/git%E5%91%BD%E4%BB%A4/"
           data-tag="git"
           data-author="" >
            <span class="post-title" title="day01-git命令">day01-git命令</span>
            <span class="post-date" title="2020-04-20 11:06:15">2020/04/20</span>
        </a>
        
        <a  class="数据库 "
           href="/2020/04/20/PostgreSQL%E4%BA%8B%E5%8A%A1%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"
           data-tag="PostgreSQL"
           data-author="" >
            <span class="post-title" title="PostgreSQL事务及隔离级别">PostgreSQL事务及隔离级别</span>
            <span class="post-date" title="2020-04-20 11:20:41">2020/04/20</span>
        </a>
        
        <a  class="数据库 "
           href="/2020/04/20/Mybatis%E5%B8%B8%E7%94%A8Mapper%E8%AF%AD%E5%8F%A5/"
           data-tag="PostgreSQL"
           data-author="" >
            <span class="post-title" title="Mybatis常用Mapper语句">Mybatis常用Mapper语句</span>
            <span class="post-date" title="2020-04-20 11:17:06">2020/04/20</span>
        </a>
        
        <a  class="小实训 "
           href="/2020/04/21/hugo%E6%93%8D%E4%BD%9C/"
           data-tag="hugo"
           data-author="" >
            <span class="post-title" title="day02-hugo操作">day02-hugo操作</span>
            <span class="post-date" title="2020-04-21 11:20:42">2020/04/21</span>
        </a>
        
        <a  class="小实训 "
           href="/2020/04/22/vue%E5%A4%8D%E4%B9%A0/"
           data-tag="vue"
           data-author="" >
            <span class="post-title" title="day03-vue复习">day03-vue复习</span>
            <span class="post-date" title="2020-04-22 12:15:42">2020/04/22</span>
        </a>
        
        <a  class="小实训 "
           href="/2020/04/23/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%81%E7%A7%BB/"
           data-tag="django"
           data-author="" >
            <span class="post-title" title="day04-数据库迁移">day04-数据库迁移</span>
            <span class="post-date" title="2020-04-23 16:26:25">2020/04/23</span>
        </a>
        
        <a  class="小实训 "
           href="/2020/04/26/%E8%8E%B7%E5%8F%96%E9%AA%8C%E8%AF%81%E7%A0%81/"
           data-tag="django"
           data-author="" >
            <span class="post-title" title="day05-获取验证码">day05-获取验证码</span>
            <span class="post-date" title="2020-04-26 15:07:52">2020/04/26</span>
        </a>
        
        <a  class="小实训 "
           href="/2020/04/27/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"
           data-tag="docker"
           data-author="" >
            <span class="post-title" title="day07-docker常用命令">day07-docker常用命令</span>
            <span class="post-date" title="2020-04-27 15:01:10">2020/04/27</span>
        </a>
        
    </nav>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div class="post">
    <div class="pjax">
        <article id="post-爬虫题库" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">爬虫题库</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            
                <a  data-rel="python">python</a>
            
        </span>
        
        
        <span class="tag">
            
            <a class="color3">爬虫</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
        创建时间:<time class="date" title='更新时间: 2020-01-09 09:57:12'>2020-01-09 08:48</time>
        
    </div>
    <div class="article-meta">
        
        <span>字数:5k</span>
        
        
        <span id="busuanzi_container_page_pv">
            阅读:<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
        <span class="top-comment" title="跳转至评论区">
            <a href="#comments">
                评论:<span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </a>
        </span>
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-http基于-tcp-ip协议"><span class="toc-text">1.http基于 tcp&#x2F;ip协议</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-百度是通用性爬虫"><span class="toc-text">2.百度是通用性爬虫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-http返回的状态码代表成功的是-200"><span class="toc-text">3.http返回的状态码代表成功的是 200</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-网页编码使用的函数式-encode"><span class="toc-text">4.网页编码使用的函数式 encode()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-解码使用的函数式是-decode"><span class="toc-text">5.解码使用的函数式是 decode()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-爬虫又叫-网页蜘蛛、网络机器人"><span class="toc-text">6.爬虫又叫 网页蜘蛛、网络机器人</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-什么是爬虫并解释其概念？"><span class="toc-text">7.什么是爬虫并解释其概念？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-http协议与-https协议的区别"><span class="toc-text">8.http协议与 https协议的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-谈谈你对-tcp协议与-udp协议的理解"><span class="toc-text">9.谈谈你对 tcp协议与 udp协议的理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-什么是-robots协议？阐述-robots协议与-爬虫的关系？"><span class="toc-text">10.什么是 robots协议？阐述 robots协议与 爬虫的关系？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-网页编码有-utf-8、gbk、gb2312"><span class="toc-text">11.网页编码有 utf-8、gbk、gb2312</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-默认端口信息：-1-Mysql：3306-2-Ssh：22-3-MongoDB：27017-4-Redis：6379-5-https：443-6-http：80"><span class="toc-text">12.默认端口信息： (1)Mysql：3306 (2)Ssh：22 (3)MongoDB：27017 (4)Redis：6379 (5)https：443 (6)http：80</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-Requests模块发送-get请求的参数："><span class="toc-text">13.Requests模块发送 get请求的参数：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-Requests模块发送-post请求的参数："><span class="toc-text">14.Requests模块发送 post请求的参数：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-简述聚焦爬虫的设计思路"><span class="toc-text">15.简述聚焦爬虫的设计思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-简述爬虫的分类及各类爬虫的概念"><span class="toc-text">16.简述爬虫的分类及各类爬虫的概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-请写出-8中常用的请求方法"><span class="toc-text">17.请写出 8中常用的请求方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-列举反爬虫机制（至少-8种）"><span class="toc-text">18.列举反爬虫机制（至少 8种）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#19-Requests发送请求时携带-headers参数及作用（至少写-3点）"><span class="toc-text">19.Requests发送请求时携带 headers参数及作用（至少写 3点）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#20-Requests向服务器发送文件时，文件的打开模式为-wb"><span class="toc-text">20.Requests向服务器发送文件时，文件的打开模式为 wb</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#21-Requests模块那个类自动封装-cookie：-session"><span class="toc-text">21.Requests模块那个类自动封装 cookie： session</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-前端页面由-html、css、JavaScript等三部分组成"><span class="toc-text">22.前端页面由 html、css、JavaScript等三部分组成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-请列举三个可以实现网页请求的库-1-Requests-2-Urllib-3-Aiohttp"><span class="toc-text">23.请列举三个可以实现网页请求的库     (1)Requests     (2)Urllib     (3)Aiohttp</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-简述-html、css、JavaScript的作用"><span class="toc-text">24.简述 html、css、JavaScript的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#25-针对-requests请求的响应对象，如何获取其文本形式，二进制形式及-json-数据"><span class="toc-text">25.针对 requests请求的响应对象，如何获取其文本形式，二进制形式及 json 数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#26-请列举三种数据持久化的方式-1-Csv-2-Json-3-Mysql-4-Mongodb-5-Redis"><span class="toc-text">26.请列举三种数据持久化的方式         (1)Csv         (2)Json         (3)Mysql         (4)Mongodb         (5)Redis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#27-正则元字符中“-”代表-匹配-任意字符，换行符除外"><span class="toc-text">27.正则元字符中“.”代表 匹配 任意字符，换行符除外</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#28-Responose-text-response-content-res-json分别获取响应数据的什么形式"><span class="toc-text">28.Responose.text,response.content,res.json分别获取响应数据的什么形式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#29-正则表达式中-和-匹配区别"><span class="toc-text">29.正则表达式中 (.)和 (.?)匹配区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#30-Re模块常用的三个匹配方法，并简述其特点"><span class="toc-text">30.Re模块常用的三个匹配方法，并简述其特点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#31-Xpath中根据索引定位节点数时，索引从-1开始"><span class="toc-text">31.Xpath中根据索引定位节点数时，索引从 1开始</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-请简述单属性多值匹配，多属性匹配概念及使用到的函数或关键字"><span class="toc-text">33.请简述单属性多值匹配，多属性匹配概念及使用到的函数或关键字</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#34-请列举爬虫中解析数据的模块（至少三种-1-Lxml-2-Bs4-3-Pyquery"><span class="toc-text">34.请列举爬虫中解析数据的模块（至少三种)         (1)Lxml         (2)Bs4         (3)Pyquery</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#35-Cookie和-session的区别"><span class="toc-text">35.Cookie和 session的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#36-将-dict转成-json串，用-json模块的函数是-json-dumps"><span class="toc-text">36.将 dict转成 json串，用 json模块的函数是         json.dumps()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#37-Json-dumps的参数-ensure-ascii的作用-避免中文乱码"><span class="toc-text">37.Json.dumps的参数 ensure_ascii的作用 避免中文乱码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#38-Xpath如何定位节点的基本语法（至少写三点）"><span class="toc-text">38.Xpath如何定位节点的基本语法（至少写三点）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#39-请描述-xpath表达式中的-div-id-”name”-和-div-id-”name”-的-含义"><span class="toc-text">39.请描述 xpath表达式中的.&#x2F;div[@id&#x3D;”name”]和.&#x2F;&#x2F;div[@id&#x3D;”name”]的 含义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#40-请写出-xpath表达式中的-text-与-text-的区别"><span class="toc-text">40.请写出 xpath表达式中的&#x2F;text()与&#x2F;&#x2F;text()的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#41-请写出-tcp-udp协议，ip协议，arp协议，http-https协议及-ftp协议分别位-于-tcp-ip五层模型的哪一层"><span class="toc-text">41.请写出 tcp&#x2F;udp协议，ip协议，arp协议，http&#x2F;https协议及 ftp协议分别位 于 tcp&#x2F;ip五层模型的哪一层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-请画出-tcp-ip五层模型"><span class="toc-text">42.请画出 tcp&#x2F;ip五层模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#43-谈谈-tcp三次握手四次挥手中为什么要三次握手"><span class="toc-text">43.谈谈 tcp三次握手四次挥手中为什么要三次握手</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#44-请写出-ftp协议，ssh协议、mysql、MongoDB、redis等协议或软件的默-认端口号"><span class="toc-text">44.请写出 ftp协议，ssh协议、mysql、MongoDB、redis等协议或软件的默 认端口号</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#45-请列举三个第三方提取数据的-Python库"><span class="toc-text">45.请列举三个第三方提取数据的 Python库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#46-Bs4的三种选择器是什么：-节点选择器、方法选择器、css选择器"><span class="toc-text">46.Bs4的三种选择器是什么：    节点选择器、方法选择器、css选择器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#47-Beautifulsoup使用步骤-From-bs4importBeautifulSoup-Soup-BeautifulSoup-res-text-’lxml’-Soup-select-‘css选择器’"><span class="toc-text">47.Beautifulsoup使用步骤 From bs4importBeautifulSoup Soup&#x3D;BeautifulSoup(res.text,’lxml’) Soup.select(‘css选择器’)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#48-请简述-bs4和-lxml的区别"><span class="toc-text">48.请简述 bs4和 lxml的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#49-请简述-bs4中-get-text-和-string的区别"><span class="toc-text">49.请简述 bs4中 get_text()和 string的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#50-Bs4对定位到的标签如何获取其直接文本，子孙节点文本和属性"><span class="toc-text">50.Bs4对定位到的标签如何获取其直接文本，子孙节点文本和属性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#51-Selenium使用-execute-script-js-执行-JS代码"><span class="toc-text">51.Selenium使用 execute_script(js)执行 JS代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#52-根据-name属性查找网页标签使用-find-element-by-name方法"><span class="toc-text">52.根据 name属性查找网页标签使用 find_element_by_name方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#53-请列举至少四种-selenium的交互操作"><span class="toc-text">53.请列举至少四种 selenium的交互操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#54-列举-selenium至少四种定位页面元素的方式"><span class="toc-text">54.列举 selenium至少四种定位页面元素的方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#55-假如实例化的浏览器对象名为-broswer-请写出该对象打开百度首页的代码-以及获取百度首页源码的代码"><span class="toc-text">55.假如实例化的浏览器对象名为 broswer,请写出该对象打开百度首页的代码 以及获取百度首页源码的代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#56-Mongodb查看当前工作的数据库的命令是-db"><span class="toc-text">56.Mongodb查看当前工作的数据库的命令是 db</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#57-Mongodb查看所有的非空数据库的命令是-showdbs"><span class="toc-text">57.Mongodb查看所有的非空数据库的命令是 showdbs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#58-Showdbs命令无法查看-空-数据库"><span class="toc-text">58.Showdbs命令无法查看 空 数据库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#59-请写出-mongodb数据的相关命令"><span class="toc-text">59.请写出 mongodb数据的相关命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#60-请列举三种关系型数据库与两种菲关系型数据库"><span class="toc-text">60.请列举三种关系型数据库与两种菲关系型数据库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#61-Mongodb数据库的优点"><span class="toc-text">61.Mongodb数据库的优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#62-请解释以下操作符的含义："><span class="toc-text">62.请解释以下操作符的含义：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#63-向-queue队列中添加元素操作为-queue-put"><span class="toc-text">63.向 queue队列中添加元素操作为 queue.put()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#64-从-queue队列获取元素的操作为-queue-get"><span class="toc-text">64.从 queue队列获取元素的操作为 queue.get()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#65-多线程爬虫共封装了几个类？每个类的作用是什么"><span class="toc-text">65.多线程爬虫共封装了几个类？每个类的作用是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#66-谈谈你对进程与线程的理解"><span class="toc-text">66.谈谈你对进程与线程的理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#67-请创建一个名为-dataqueueu的队列，并向其中添加一个字符串-s-’hello-queue’的代码"><span class="toc-text">67.请创建一个名为 dataqueueu的队列，并向其中添加一个字符串 s&#x3D;’hello queue’的代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#68-请简单绘制多线程爬虫的架构原理图"><span class="toc-text">68.请简单绘制多线程爬虫的架构原理图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#69-简述什么是-i-o密集型和计算密集型"><span class="toc-text">69.简述什么是 i&#x2F;o密集型和计算密集型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#70-创建一个-scrapy项目的命令是-scrapy-startproject-项目名"><span class="toc-text">70.创建一个 scrapy项目的命令是  scrapy  startproject  项目名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#71-Scrapy项目运行的命令是-scrapy-crawl-项目名"><span class="toc-text">71.Scrapy项目运行的命令是  scrapy  crawl   项目名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#72-Scrapy框架创建爬虫文件的命令为-scrapy-genspider-爬虫名-www-baidu-com"><span class="toc-text">72.Scrapy框架创建爬虫文件的命令为  scrapy  genspider  爬虫名   www.baidu.com</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#73-简述-scrapy五大核心组件及作用"><span class="toc-text">73.简述 scrapy五大核心组件及作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#74-Scrapy框架有哪些优点"><span class="toc-text">74.Scrapy框架有哪些优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#75-Scrapy基于-Twisted异步-框架"><span class="toc-text">75.Scrapy基于 Twisted异步 框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#76-Allowed-domains的作用是-限制爬虫爬取的范围"><span class="toc-text">76.Allowed_domains的作用是 限制爬虫爬取的范围</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#77-请简述-scrapy框架五大核心组件有哪些"><span class="toc-text">77.请简述 scrapy框架五大核心组件有哪些</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#78-如何判断-scrapy管道类是否需要-returnitem"><span class="toc-text">78.如何判断 scrapy管道类是否需要 returnitem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#79-请问为什么下载器返回的相应数据不是直接通过引擎传递给管道，而是传递-给-spider"><span class="toc-text">79.请问为什么下载器返回的相应数据不是直接通过引擎传递给管道，而是传递 给 spider</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#80-在-scrapy框架中手动发起请求时，使用-meta-参数给解析方法传递数据"><span class="toc-text">80.在 scrapy框架中手动发起请求时，使用 meta 参数给解析方法传递数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#81-Scrapy框架发送-post请求使用-FormRequest-方法"><span class="toc-text">81.Scrapy框架发送 post请求使用 FormRequest 方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#82-请简述scrapy阻止对start-urls内url主动发送请求时重写的父类方法名称，-及使用-scrapy-request的常用参数及含义"><span class="toc-text">82.请简述scrapy阻止对start_urls内url主动发送请求时重写的父类方法名称， 及使用 scrapy.request的常用参数及含义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#83-简述详情页爬取的思路"><span class="toc-text">83.简述详情页爬取的思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#85-安装-scrapy框架的命令为-pipinstall-scrapy"><span class="toc-text">85.安装 scrapy框架的命令为 pipinstall  scrapy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#86-Scrapy框架管道必须实现的方法是-process-item"><span class="toc-text">86.Scrapy框架管道必须实现的方法是 process_item</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#87-请使用-fake-useragent模块实现一个简单的-ua池"><span class="toc-text">87.请使用 fake_useragent模块实现一个简单的 ua池</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#88-Scrapy框架中间件的分类及其作用"><span class="toc-text">88.Scrapy框架中间件的分类及其作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#89-Scrapy框架下载中间件的核心方法及其作用"><span class="toc-text">89.Scrapy框架下载中间件的核心方法及其作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#90-修改-scrapy项目的配置需要修改-settings-文件"><span class="toc-text">90.修改 scrapy项目的配置需要修改 settings 文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#91-应用-selenium框架实例化浏览器对象时，使用-executable-path-参数指-定驱动路径"><span class="toc-text">91.应用 selenium框架实例化浏览器对象时，使用 executable_path 参数指 定驱动路径</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#92-动态数据加载的两种情况及相应的解决方案"><span class="toc-text">92.动态数据加载的两种情况及相应的解决方案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#93-简述-selenium与-scrapy框架对接实现动态加载数据的爬取思路"><span class="toc-text">93.简述 selenium与 scrapy框架对接实现动态加载数据的爬取思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#94-请写出-selenium的常用节点交互操作（至少-5条）"><span class="toc-text">94.请写出 selenium的常用节点交互操作（至少 5条）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#95-创建基于-crawl的全站爬虫的命令"><span class="toc-text">95.创建基于 crawl的全站爬虫的命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#96-简述-pipeline的核心方法及各方法实现什么功能"><span class="toc-text">96.简述 pipeline的核心方法及各方法实现什么功能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#97-Scrapy原生框架实现分布式要依赖哪个组件？该组件解决了什么问题"><span class="toc-text">97.Scrapy原生框架实现分布式要依赖哪个组件？该组件解决了什么问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#98-列举三种常用的网络数据爬取的模块或框架"><span class="toc-text">98.列举三种常用的网络数据爬取的模块或框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#99-请谈谈动态数据加载的爬取思路"><span class="toc-text">99.请谈谈动态数据加载的爬取思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#100-请列举-5种反爬机制及其对应的反反爬-策略"><span class="toc-text">100.请列举 5种反爬机制及其对应的反反爬 策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#102-请写出爬虫-数据持久化-Python与-mongodb数据库的交互编码"><span class="toc-text">102.请写出爬虫 数据持久化 Python与 mongodb数据库的交互编码</span></a></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="1-http基于-tcp-ip协议"><a href="#1-http基于-tcp-ip协议" class="headerlink" title="1.http基于 tcp/ip协议"></a>1.http基于 tcp/ip协议</h3><h3 id="2-百度是通用性爬虫"><a href="#2-百度是通用性爬虫" class="headerlink" title="2.百度是通用性爬虫"></a>2.百度是通用性爬虫</h3><h3 id="3-http返回的状态码代表成功的是-200"><a href="#3-http返回的状态码代表成功的是-200" class="headerlink" title="3.http返回的状态码代表成功的是 200"></a>3.http返回的状态码代表成功的是 200</h3><h3 id="4-网页编码使用的函数式-encode"><a href="#4-网页编码使用的函数式-encode" class="headerlink" title="4.网页编码使用的函数式 encode()"></a>4.网页编码使用的函数式 encode()</h3><h3 id="5-解码使用的函数式是-decode"><a href="#5-解码使用的函数式是-decode" class="headerlink" title="5.解码使用的函数式是 decode()"></a>5.解码使用的函数式是 decode()</h3><h3 id="6-爬虫又叫-网页蜘蛛、网络机器人"><a href="#6-爬虫又叫-网页蜘蛛、网络机器人" class="headerlink" title="6.爬虫又叫 网页蜘蛛、网络机器人"></a>6.爬虫又叫 网页蜘蛛、网络机器人</h3><h3 id="7-什么是爬虫并解释其概念？"><a href="#7-什么是爬虫并解释其概念？" class="headerlink" title="7.什么是爬虫并解释其概念？"></a>7.什么是爬虫并解释其概念？</h3><p>​        (1)爬虫又叫网页蜘蛛，是模拟人操作客户端向服务器发起请求，抓取数据 的自动化程序或脚本 </p>
<p>​        (2)说明： ① 模拟：用爬虫程序伪装出人的行为，避免被服务器识别为爬虫程序 ② 客户端：浏览器、app都可以实现        人与服务器之间的交互行为，应 用客户端从服务器获取数据 ③ 自动化：数据量较小可以人工获取，但往往在公司        里爬取的数据量 在百万条、千万条级别，所以要程序自动化获取数据 </p>
<h3 id="8-http协议与-https协议的区别"><a href="#8-http协议与-https协议的区别" class="headerlink" title="8.http协议与 https协议的区别"></a>8.http协议与 https协议的区别</h3><p>​        1.https协议需要到 ca申请证书，一般免费证书较少，因而需要一定费用 </p>
<p>​        2.http是超文本传输协议，信息是明文传输，https则是具有安全性的 ssl 加密传输协议 </p>
<p>​        3.http和 https使用的是完全不同的连接方式，用的端口不一样，前者是 80， 后者是 443 </p>
<p>​        4.http的连接很简单，是无状态的，https协议是有 ssl+http协议构建的可 进行加密传输、身份认证的网络协议,http协        议安全.</p>
<h3 id="9-谈谈你对-tcp协议与-udp协议的理解"><a href="#9-谈谈你对-tcp协议与-udp协议的理解" class="headerlink" title="9.谈谈你对 tcp协议与 udp协议的理解"></a>9.谈谈你对 tcp协议与 udp协议的理解</h3><p>​        (1)两者都是传输层协议</p>
<p>​         (2)Tcp协议，是一种面向连接的，可靠的，基于字节流的传输层通信协议， 其具有以下 4个特性： ① 有序性 ② 正         确性 ③ 可靠性 ④ 可控性 </p>
<p>​        (3)Udp协议，是用户数据协议，面向无连接的传输层协议，传输不可靠， 其具有以下 3个特点： ① 无链接，数据可        能丢失或损坏 ② 报文小，传输速度快 ③ 吞吐量大的网络传输，可以在一定程度上承受数据丢失 </p>
<h3 id="10-什么是-robots协议？阐述-robots协议与-爬虫的关系？"><a href="#10-什么是-robots协议？阐述-robots协议与-爬虫的关系？" class="headerlink" title="10.什么是 robots协议？阐述 robots协议与 爬虫的关系？"></a>10.什么是 robots协议？阐述 robots协议与 爬虫的关系？</h3><p>​        (1)Robots协议是 约定哪些内容允许哪些爬虫抓取 </p>
<p>​        (2)通用爬虫无需遵守 robots协议，而我们写的聚焦爬虫则需要遵守 </p>
<h3 id="11-网页编码有-utf-8、gbk、gb2312"><a href="#11-网页编码有-utf-8、gbk、gb2312" class="headerlink" title="11.网页编码有 utf-8、gbk、gb2312"></a>11.网页编码有 utf-8、gbk、gb2312</h3><h3 id="12-默认端口信息：-1-Mysql：3306-2-Ssh：22-3-MongoDB：27017-4-Redis：6379-5-https：443-6-http：80"><a href="#12-默认端口信息：-1-Mysql：3306-2-Ssh：22-3-MongoDB：27017-4-Redis：6379-5-https：443-6-http：80" class="headerlink" title="12.默认端口信息： (1)Mysql：3306 (2)Ssh：22 (3)MongoDB：27017 (4)Redis：6379 (5)https：443 (6)http：80"></a>12.默认端口信息： (1)Mysql：3306 (2)Ssh：22 (3)MongoDB：27017 (4)Redis：6379 (5)https：443 (6)http：80</h3><h3 id="13-Requests模块发送-get请求的参数："><a href="#13-Requests模块发送-get请求的参数：" class="headerlink" title="13.Requests模块发送 get请求的参数："></a>13.Requests模块发送 get请求的参数：</h3><p>​        (1)Url         (2)Headers         (3)Params         (4)Proxies </p>
<h3 id="14-Requests模块发送-post请求的参数："><a href="#14-Requests模块发送-post请求的参数：" class="headerlink" title="14.Requests模块发送 post请求的参数："></a>14.Requests模块发送 post请求的参数：</h3><p>​        (1)Url         (2)Headers         (3)Data         (4)Proxies </p>
<h3 id="15-简述聚焦爬虫的设计思路"><a href="#15-简述聚焦爬虫的设计思路" class="headerlink" title="15.简述聚焦爬虫的设计思路"></a>15.简述聚焦爬虫的设计思路</h3><p>​        (1)确定 url，模拟浏览器向服务器发送请求 </p>
<p>​        (2)获取响应数据并进行数据解析 </p>
<p>​        (3)将目标数据持久化到本地 </p>
<h3 id="16-简述爬虫的分类及各类爬虫的概念"><a href="#16-简述爬虫的分类及各类爬虫的概念" class="headerlink" title="16.简述爬虫的分类及各类爬虫的概念"></a>16.简述爬虫的分类及各类爬虫的概念</h3><p>​        (1)通用爬虫：爬取网页数据，为搜索引擎提供检索服务 </p>
<p>​        (2)聚焦爬虫：针对某一领域爬取特定数据的爬虫 ① 聚焦爬虫又分为深度爬虫和增量式爬虫 </p>
<h3 id="17-请写出-8中常用的请求方法"><a href="#17-请写出-8中常用的请求方法" class="headerlink" title="17.请写出 8中常用的请求方法"></a>17.请写出 8中常用的请求方法</h3><p>​        (1)Get         (2)Post         (3)Put         (4)Delete         (5)Trace         (6)Head         (7)Connect         (8)Options </p>
<h3 id="18-列举反爬虫机制（至少-8种）"><a href="#18-列举反爬虫机制（至少-8种）" class="headerlink" title="18.列举反爬虫机制（至少 8种）"></a>18.列举反爬虫机制（至少 8种）</h3><p>​        (1)UA检测        (2)Robots协议        (3)验证码        (4)IP封禁        (5)账号封禁        (6)动态数据加载                                              </p>
<p>​        (7)Js数据加密        (8)隐藏参数         (9)字体反爬 </p>
<h3 id="19-Requests发送请求时携带-headers参数及作用（至少写-3点）"><a href="#19-Requests发送请求时携带-headers参数及作用（至少写-3点）" class="headerlink" title="19.Requests发送请求时携带 headers参数及作用（至少写 3点）"></a>19.Requests发送请求时携带 headers参数及作用（至少写 3点）</h3><p>​        (1)User-Agent：实现 UA伪装 </p>
<p>​        (2)Cookie：模拟登陆 </p>
<p>​        (3)Connection：保持连接 </p>
<p>​        (4)Accept：接受数据类型 </p>
<h3 id="20-Requests向服务器发送文件时，文件的打开模式为-wb"><a href="#20-Requests向服务器发送文件时，文件的打开模式为-wb" class="headerlink" title="20.Requests向服务器发送文件时，文件的打开模式为 wb"></a>20.Requests向服务器发送文件时，文件的打开模式为 wb</h3><h3 id="21-Requests模块那个类自动封装-cookie：-session"><a href="#21-Requests模块那个类自动封装-cookie：-session" class="headerlink" title="21.Requests模块那个类自动封装 cookie： session"></a>21.Requests模块那个类自动封装 cookie： session</h3><h3 id="22-前端页面由-html、css、JavaScript等三部分组成"><a href="#22-前端页面由-html、css、JavaScript等三部分组成" class="headerlink" title="22.前端页面由 html、css、JavaScript等三部分组成"></a>22.前端页面由 html、css、JavaScript等三部分组成</h3><h3 id="23-请列举三个可以实现网页请求的库-1-Requests-2-Urllib-3-Aiohttp"><a href="#23-请列举三个可以实现网页请求的库-1-Requests-2-Urllib-3-Aiohttp" class="headerlink" title="23.请列举三个可以实现网页请求的库     (1)Requests     (2)Urllib     (3)Aiohttp"></a>23.请列举三个可以实现网页请求的库     (1)Requests     (2)Urllib     (3)Aiohttp</h3><h3 id="24-简述-html、css、JavaScript的作用"><a href="#24-简述-html、css、JavaScript的作用" class="headerlink" title="24.简述 html、css、JavaScript的作用"></a>24.简述 html、css、JavaScript的作用</h3><p>​        (1)Html：定义网页骨架 </p>
<p>​        (2)Css：定义网页样式 </p>
<p>​        (3)JavaScript：定义网页行为 </p>
<h3 id="25-针对-requests请求的响应对象，如何获取其文本形式，二进制形式及-json-数据"><a href="#25-针对-requests请求的响应对象，如何获取其文本形式，二进制形式及-json-数据" class="headerlink" title="25.针对 requests请求的响应对象，如何获取其文本形式，二进制形式及 json 数据"></a>25.针对 requests请求的响应对象，如何获取其文本形式，二进制形式及 json 数据</h3><p>​        (1)Res.text：获取 html源码 </p>
<p>​        (2)Res.content：获取二进制流，多用于图片、视频下载等 </p>
<p>​        (3)Res.json()：获取 json数据，多用 ajax请求 </p>
<h3 id="26-请列举三种数据持久化的方式-1-Csv-2-Json-3-Mysql-4-Mongodb-5-Redis"><a href="#26-请列举三种数据持久化的方式-1-Csv-2-Json-3-Mysql-4-Mongodb-5-Redis" class="headerlink" title="26.请列举三种数据持久化的方式         (1)Csv         (2)Json         (3)Mysql         (4)Mongodb         (5)Redis"></a>26.请列举三种数据持久化的方式         (1)Csv         (2)Json         (3)Mysql         (4)Mongodb         (5)Redis</h3><h3 id="27-正则元字符中“-”代表-匹配-任意字符，换行符除外"><a href="#27-正则元字符中“-”代表-匹配-任意字符，换行符除外" class="headerlink" title="27.正则元字符中“.”代表 匹配 任意字符，换行符除外"></a>27.正则元字符中“.”代表 匹配 任意字符，换行符除外</h3><h3 id="28-Responose-text-response-content-res-json分别获取响应数据的什么形式"><a href="#28-Responose-text-response-content-res-json分别获取响应数据的什么形式" class="headerlink" title="28.Responose.text,response.content,res.json分别获取响应数据的什么形式"></a>28.Responose.text,response.content,res.json分别获取响应数据的什么形式</h3><p>​        (1)Response.text：文本形式 </p>
<p>​        (2)Response.json()：json数据 </p>
<p>​        (3)Response.content：二进制形式 </p>
<h3 id="29-正则表达式中-和-匹配区别"><a href="#29-正则表达式中-和-匹配区别" class="headerlink" title="29.正则表达式中 (.)和 (.?)匹配区别"></a>29.正则表达式中 (.<em>)和 (.</em>?)匹配区别</h3><p>​        (1)（.*）：贪婪匹配，尽可能多的匹配 *</p>
<p>​        <em>(2)（.</em>？）：非贪婪匹配，尽可能少的匹配 </p>
<h3 id="30-Re模块常用的三个匹配方法，并简述其特点"><a href="#30-Re模块常用的三个匹配方法，并简述其特点" class="headerlink" title="30.Re模块常用的三个匹配方法，并简述其特点"></a>30.Re模块常用的三个匹配方法，并简述其特点</h3><p>​        (1)Re.findall()：以列表形式返回所有满足条件的对象 </p>
<p>​        (2)Re.search()：匹配到第一个就返回一个对象 ，用 group（）取值，匹 配不到返回 None </p>
<p>​        (3)Re.match()：从字符串开头匹配，匹配返回一个对象，用 group（）取 值，匹配不到返回 None </p>
<h3 id="31-Xpath中根据索引定位节点数时，索引从-1开始"><a href="#31-Xpath中根据索引定位节点数时，索引从-1开始" class="headerlink" title="31.Xpath中根据索引定位节点数时，索引从 1开始"></a>31.Xpath中根据索引定位节点数时，索引从 1开始</h3><p>32.Xpath中的 contains（）函数的第一个参数是 @属性名 ，第二个参数是 属性包含的值 </p>
<h3 id="33-请简述单属性多值匹配，多属性匹配概念及使用到的函数或关键字"><a href="#33-请简述单属性多值匹配，多属性匹配概念及使用到的函数或关键字" class="headerlink" title="33.请简述单属性多值匹配，多属性匹配概念及使用到的函数或关键字"></a>33.请简述单属性多值匹配，多属性匹配概念及使用到的函数或关键字</h3><p>​        (1)单属性多值匹配：根据节点某属性包含的某个值进行定位，使用 contains函数 </p>
<p>​        (2)多属性匹配：根据节点的多个属性，共同定位该节点，使用关键字 and </p>
<h3 id="34-请列举爬虫中解析数据的模块（至少三种-1-Lxml-2-Bs4-3-Pyquery"><a href="#34-请列举爬虫中解析数据的模块（至少三种-1-Lxml-2-Bs4-3-Pyquery" class="headerlink" title="34.请列举爬虫中解析数据的模块（至少三种)         (1)Lxml         (2)Bs4         (3)Pyquery"></a>34.请列举爬虫中解析数据的模块（至少三种)         (1)Lxml         (2)Bs4         (3)Pyquery</h3><h3 id="35-Cookie和-session的区别"><a href="#35-Cookie和-session的区别" class="headerlink" title="35.Cookie和 session的区别"></a>35.Cookie和 session的区别</h3><p>​        (1)数据存储位置不同，cookie存在客户端，session存在服务器 </p>
<p>​        (2)安全程度不同，cookie存客户端本地，分析 cookie，实现 cookie欺骗， 考虑到安全性，所以用 session</p>
<pre><code>     (3)性能不同，session存服务器，访问量大时，会增加服务器负载，考虑 到性能，所以用 cookie </code></pre><p>​        (4)数据存储大小不同，单个 cookie不超过 4k，部分浏览器会限制 cookie 的存储个数，但 session存在服务器，故不        受客户端浏览器限制 </p>
<h3 id="36-将-dict转成-json串，用-json模块的函数是-json-dumps"><a href="#36-将-dict转成-json串，用-json模块的函数是-json-dumps" class="headerlink" title="36.将 dict转成 json串，用 json模块的函数是         json.dumps()"></a>36.将 dict转成 json串，用 json模块的函数是         json.dumps()</h3><h3 id="37-Json-dumps的参数-ensure-ascii的作用-避免中文乱码"><a href="#37-Json-dumps的参数-ensure-ascii的作用-避免中文乱码" class="headerlink" title="37.Json.dumps的参数 ensure_ascii的作用 避免中文乱码"></a>37.Json.dumps的参数 ensure_ascii的作用 避免中文乱码</h3><h3 id="38-Xpath如何定位节点的基本语法（至少写三点）"><a href="#38-Xpath如何定位节点的基本语法（至少写三点）" class="headerlink" title="38.Xpath如何定位节点的基本语法（至少写三点）"></a>38.Xpath如何定位节点的基本语法（至少写三点）</h3><p>​        (1)根据节点名定位：nodename </p>
<p>​        (2)根据节点属性定位：nodename[@attribute=”value”] </p>
<p>​        (3)从当前节点的根节点向下匹配： ./ </p>
<p>​        (4)从当前节点的任意位置向下匹配： .// </p>
<h3 id="39-请描述-xpath表达式中的-div-id-”name”-和-div-id-”name”-的-含义"><a href="#39-请描述-xpath表达式中的-div-id-”name”-和-div-id-”name”-的-含义" class="headerlink" title="39.请描述 xpath表达式中的./div[@id=”name”]和.//div[@id=”name”]的 含义"></a>39.请描述 xpath表达式中的./div[@id=”name”]和.//div[@id=”name”]的 含义</h3><p>​        (1)从当前节点的根节点向下匹配，匹配一个 div标签，该 div标签的 id属 性值是“name” </p>
<p>​        (2)从当前节点的任意位置向下匹配，匹配一个 div标签，该 div标签的 id 属性值是“name” </p>
<h3 id="40-请写出-xpath表达式中的-text-与-text-的区别"><a href="#40-请写出-xpath表达式中的-text-与-text-的区别" class="headerlink" title="40.请写出 xpath表达式中的/text()与//text()的区别"></a>40.请写出 xpath表达式中的/text()与//text()的区别</h3><p>(1)/text()：获取已定位节点的直接子文本 </p>
<p>(2)//text()：获取已定节点的子孙节点文本 </p>
<h3 id="41-请写出-tcp-udp协议，ip协议，arp协议，http-https协议及-ftp协议分别位-于-tcp-ip五层模型的哪一层"><a href="#41-请写出-tcp-udp协议，ip协议，arp协议，http-https协议及-ftp协议分别位-于-tcp-ip五层模型的哪一层" class="headerlink" title="41.请写出 tcp/udp协议，ip协议，arp协议，http/https协议及 ftp协议分别位 于 tcp/ip五层模型的哪一层"></a>41.请写出 tcp/udp协议，ip协议，arp协议，http/https协议及 ftp协议分别位 于 tcp/ip五层模型的哪一层</h3><p>​        (1)TCP/UDP协议：传输层 </p>
<p>​        (2)IP：网络层 </p>
<p>​        (3)ARP协议：数据链路层 </p>
<p>​        (4)HTTP/HTTPS：应用层 </p>
<p>​        (5)FTP协议：应用层 </p>
<h3 id="42-请画出-tcp-ip五层模型"><a href="#42-请画出-tcp-ip五层模型" class="headerlink" title="42.请画出 tcp/ip五层模型"></a>42.请画出 tcp/ip五层模型</h3><p>​        (1)应用层         (2)传输层         (3)网络层         (4)数据链路层         (5)物理层 </p>
<h3 id="43-谈谈-tcp三次握手四次挥手中为什么要三次握手"><a href="#43-谈谈-tcp三次握手四次挥手中为什么要三次握手" class="headerlink" title="43.谈谈 tcp三次握手四次挥手中为什么要三次握手"></a>43.谈谈 tcp三次握手四次挥手中为什么要三次握手</h3><p>​        (1)TCP连接的三次握手是为了建立可靠的连接 </p>
<p>​        (2)第一次握手：客户端向服务器发送 SYN包，并进入 SYN_SENF状态， 等待服务器确认 </p>
<p>​        (3)第二次握手：服务器收到 SYN包，确认并发送 SYN+ACK包，同时进 入 SYN_RECV状态 </p>
<p>​        (4)第三次握手：客户端收到服务器 SYN+ACK包，向服务器确认 ACK包， 进入 ESTABLISHED状态 </p>
<h3 id="44-请写出-ftp协议，ssh协议、mysql、MongoDB、redis等协议或软件的默-认端口号"><a href="#44-请写出-ftp协议，ssh协议、mysql、MongoDB、redis等协议或软件的默-认端口号" class="headerlink" title="44.请写出 ftp协议，ssh协议、mysql、MongoDB、redis等协议或软件的默 认端口号"></a>44.请写出 ftp协议，ssh协议、mysql、MongoDB、redis等协议或软件的默 认端口号</h3><p>​        (1)ftp：21     (2)Ssh：22     (3)Mysql：3306     (4)Mongodb：27017     (5)Redis：6379 </p>
<h3 id="45-请列举三个第三方提取数据的-Python库"><a href="#45-请列举三个第三方提取数据的-Python库" class="headerlink" title="45.请列举三个第三方提取数据的 Python库"></a>45.请列举三个第三方提取数据的 Python库</h3><p>​        (1)Wxpython         (2)Py2exe         (3)Psyco         (4)Mysqldb         (5)pyprocessing </p>
<h3 id="46-Bs4的三种选择器是什么：-节点选择器、方法选择器、css选择器"><a href="#46-Bs4的三种选择器是什么：-节点选择器、方法选择器、css选择器" class="headerlink" title="46.Bs4的三种选择器是什么：    节点选择器、方法选择器、css选择器"></a>46.Bs4的三种选择器是什么：    节点选择器、方法选择器、css选择器</h3><h3 id="47-Beautifulsoup使用步骤-From-bs4importBeautifulSoup-Soup-BeautifulSoup-res-text-’lxml’-Soup-select-‘css选择器’"><a href="#47-Beautifulsoup使用步骤-From-bs4importBeautifulSoup-Soup-BeautifulSoup-res-text-’lxml’-Soup-select-‘css选择器’" class="headerlink" title="47.Beautifulsoup使用步骤 From bs4importBeautifulSoup Soup=BeautifulSoup(res.text,’lxml’) Soup.select(‘css选择器’)"></a>47.Beautifulsoup使用步骤 From bs4importBeautifulSoup Soup=BeautifulSoup(res.text,’lxml’) Soup.select(‘css选择器’)</h3><h3 id="48-请简述-bs4和-lxml的区别"><a href="#48-请简述-bs4和-lxml的区别" class="headerlink" title="48.请简述 bs4和 lxml的区别"></a>48.请简述 bs4和 lxml的区别</h3><p>​        (1)bs4会将整个文档树进行加载然后进行查询匹配操作，使用过程中消耗 资源较多 </p>
<p>​        (2)lxml是 python的一个解析库，支持 HTML和 XML的解析，支持 XPath 解析方式，而且解析效率非常高,功能更强大 </p>
<h3 id="49-请简述-bs4中-get-text-和-string的区别"><a href="#49-请简述-bs4中-get-text-和-string的区别" class="headerlink" title="49.请简述 bs4中 get_text()和 string的区别"></a>49.请简述 bs4中 get_text()和 string的区别</h3><p>​        (1)String:获取节点的直接子文本 </p>
<p>​        (2)get_text()：获取节点下子孙节点文本 </p>
<h3 id="50-Bs4对定位到的标签如何获取其直接文本，子孙节点文本和属性"><a href="#50-Bs4对定位到的标签如何获取其直接文本，子孙节点文本和属性" class="headerlink" title="50.Bs4对定位到的标签如何获取其直接文本，子孙节点文本和属性"></a>50.Bs4对定位到的标签如何获取其直接文本，子孙节点文本和属性</h3><p>​        (1)直接子文本：string         (2)子孙节点文本：get_text()         (3)属性：tag[“attribute”] </p>
<h3 id="51-Selenium使用-execute-script-js-执行-JS代码"><a href="#51-Selenium使用-execute-script-js-执行-JS代码" class="headerlink" title="51.Selenium使用 execute_script(js)执行 JS代码"></a>51.Selenium使用 execute_script(js)执行 JS代码</h3><h3 id="52-根据-name属性查找网页标签使用-find-element-by-name方法"><a href="#52-根据-name属性查找网页标签使用-find-element-by-name方法" class="headerlink" title="52.根据 name属性查找网页标签使用 find_element_by_name方法"></a>52.根据 name属性查找网页标签使用 find_element_by_name方法</h3><h3 id="53-请列举至少四种-selenium的交互操作"><a href="#53-请列举至少四种-selenium的交互操作" class="headerlink" title="53.请列举至少四种 selenium的交互操作"></a>53.请列举至少四种 selenium的交互操作</h3><p>​        (1)Clear()         (2)Click()         (3)Send_keys()         (4)Double_click() </p>
<h3 id="54-列举-selenium至少四种定位页面元素的方式"><a href="#54-列举-selenium至少四种定位页面元素的方式" class="headerlink" title="54.列举 selenium至少四种定位页面元素的方式"></a>54.列举 selenium至少四种定位页面元素的方式</h3><p>​        (1)Find_element_by_name </p>
<p>​        (2)Find_element_by_id </p>
<p>​        (3)Find_element_by_xpath </p>
<p>​        (4)Find_element_css_selector </p>
<h3 id="55-假如实例化的浏览器对象名为-broswer-请写出该对象打开百度首页的代码-以及获取百度首页源码的代码"><a href="#55-假如实例化的浏览器对象名为-broswer-请写出该对象打开百度首页的代码-以及获取百度首页源码的代码" class="headerlink" title="55.假如实例化的浏览器对象名为 broswer,请写出该对象打开百度首页的代码 以及获取百度首页源码的代码"></a>55.假如实例化的浏览器对象名为 broswer,请写出该对象打开百度首页的代码 以及获取百度首页源码的代码</h3><pre><code class="python">from selenium import webdriver 
Borwser=webdriver.chrome(“dirverpath”) 
Borwser.get(“http://www.baidu.com”) 
Html=browser.page_source 
print(Html)</code></pre>
<h3 id="56-Mongodb查看当前工作的数据库的命令是-db"><a href="#56-Mongodb查看当前工作的数据库的命令是-db" class="headerlink" title="56.Mongodb查看当前工作的数据库的命令是 db"></a>56.Mongodb查看当前工作的数据库的命令是 db</h3><h3 id="57-Mongodb查看所有的非空数据库的命令是-showdbs"><a href="#57-Mongodb查看所有的非空数据库的命令是-showdbs" class="headerlink" title="57.Mongodb查看所有的非空数据库的命令是 showdbs"></a>57.Mongodb查看所有的非空数据库的命令是 showdbs</h3><h3 id="58-Showdbs命令无法查看-空-数据库"><a href="#58-Showdbs命令无法查看-空-数据库" class="headerlink" title="58.Showdbs命令无法查看 空 数据库"></a>58.Showdbs命令无法查看 空 数据库</h3><h3 id="59-请写出-mongodb数据的相关命令"><a href="#59-请写出-mongodb数据的相关命令" class="headerlink" title="59.请写出 mongodb数据的相关命令"></a>59.请写出 mongodb数据的相关命令</h3><p>​        创建并使用集合:usexxx </p>
<p>​        查看当前工作的集合:db </p>
<p>​        查看所有非空集合： showdbs </p>
<p>​        查看当前集合的所有数据：db.table.find() </p>
<h3 id="60-请列举三种关系型数据库与两种菲关系型数据库"><a href="#60-请列举三种关系型数据库与两种菲关系型数据库" class="headerlink" title="60.请列举三种关系型数据库与两种菲关系型数据库"></a>60.请列举三种关系型数据库与两种菲关系型数据库</h3><p>​        (1)关系型数据库：Mysql、orcale、sql_server </p>
<p>​        (2)非关系数据库：redis、mongodb </p>
<h3 id="61-Mongodb数据库的优点"><a href="#61-Mongodb数据库的优点" class="headerlink" title="61.Mongodb数据库的优点"></a>61.Mongodb数据库的优点</h3><p>​        (1)模式自由，面向集合存储，项目增删字段不影响程序运行 </p>
<p>​        (2)具有丰富的查询表达式，支持动态查询，以满足项目的数据查询需求 </p>
<p>​        (3)良好的索引支持，文档内嵌对象和数组，均可创建索引 </p>
<p>​        (4) 支持二进制数据存储，可以将图片视频等文件转换为二进制流存储 起来 </p>
<p>​        (5)以内存映射为存储引擎，大幅度提升性能 </p>
<h3 id="62-请解释以下操作符的含义："><a href="#62-请解释以下操作符的含义：" class="headerlink" title="62.请解释以下操作符的含义："></a>62.请解释以下操作符的含义：</h3><p>​        (1) $gt: &gt;     (2) $lt: &lt;     (3) $gte: &gt;=     (4) $lte: &lt;=     (5) $ne: ≠     (6)$in: 在其中     (7) $nin: 不在其中     (8) $or: 或 </p>
<h3 id="63-向-queue队列中添加元素操作为-queue-put"><a href="#63-向-queue队列中添加元素操作为-queue-put" class="headerlink" title="63.向 queue队列中添加元素操作为 queue.put()"></a>63.向 queue队列中添加元素操作为 queue.put()</h3><h3 id="64-从-queue队列获取元素的操作为-queue-get"><a href="#64-从-queue队列获取元素的操作为-queue-get" class="headerlink" title="64.从 queue队列获取元素的操作为 queue.get()"></a>64.从 queue队列获取元素的操作为 queue.get()</h3><h3 id="65-多线程爬虫共封装了几个类？每个类的作用是什么"><a href="#65-多线程爬虫共封装了几个类？每个类的作用是什么" class="headerlink" title="65.多线程爬虫共封装了几个类？每个类的作用是什么"></a>65.多线程爬虫共封装了几个类？每个类的作用是什么</h3><p>​        (1) 两个类：爬虫类、解析类 </p>
<p>​        (2) 爬虫类；定义爬取的行为，将响应数据提交给响应数据队列 </p>
<p>​        (3) 解析类：定义数据解析规则并与数据库交互，将数据持久化进数据 库 </p>
<h3 id="66-谈谈你对进程与线程的理解"><a href="#66-谈谈你对进程与线程的理解" class="headerlink" title="66.谈谈你对进程与线程的理解"></a>66.谈谈你对进程与线程的理解</h3><p>​        (1) 进程是操作系统将资源分配的基本单位，而线程是任务调度执行的 基本单位 </p>
<p>​        (2) 线程是进程的一部分，一个线程只能属于一个进程，而一个进程可 以有多个线程，但至少要有一个线程 </p>
<p>​        (3) 进程都有独立的代码和数据空间，切换开销大，而线程共享代码与 数据空间，切换开销小 </p>
<h3 id="67-请创建一个名为-dataqueueu的队列，并向其中添加一个字符串-s-’hello-queue’的代码"><a href="#67-请创建一个名为-dataqueueu的队列，并向其中添加一个字符串-s-’hello-queue’的代码" class="headerlink" title="67.请创建一个名为 dataqueueu的队列，并向其中添加一个字符串 s=’hello queue’的代码"></a>67.请创建一个名为 dataqueueu的队列，并向其中添加一个字符串 s=’hello queue’的代码</h3><pre><code class="python">from queue import Queue 
Q=Queue() 
S=“helloqueue” 
Q.put(s) </code></pre>
<h3 id="68-请简单绘制多线程爬虫的架构原理图"><a href="#68-请简单绘制多线程爬虫的架构原理图" class="headerlink" title="68.请简单绘制多线程爬虫的架构原理图"></a>68.请简单绘制多线程爬虫的架构原理图</h3><p>​        Urlqueue—–&gt;爬虫线程——&gt;Internet—–&gt;DataQueue——&gt;解析 线程——-&gt;database </p>
<h3 id="69-简述什么是-i-o密集型和计算密集型"><a href="#69-简述什么是-i-o密集型和计算密集型" class="headerlink" title="69.简述什么是 i/o密集型和计算密集型"></a>69.简述什么是 i/o密集型和计算密集型</h3><p>​        (1) Io密集型是指程序运行时，大部分状况是 CPU在等待 i/o，即磁盘 读写，其特点是程序达到性能极限时，CPU占        用率依然很低，涉及到网 络，磁盘 ID的任务都是 io密集型 </p>
<p>​        (2) 计算密集型，又称 CPU密集型，即程序运行过程中，IO操作很短时 间内完成,而 CPU占用很大，有许多运算要处        理，其特点是要进行大量 的运算，消耗 CPU资源 </p>
<h3 id="70-创建一个-scrapy项目的命令是-scrapy-startproject-项目名"><a href="#70-创建一个-scrapy项目的命令是-scrapy-startproject-项目名" class="headerlink" title="70.创建一个 scrapy项目的命令是  scrapy  startproject  项目名"></a>70.创建一个 scrapy项目的命令是  scrapy  startproject  项目名</h3><h3 id="71-Scrapy项目运行的命令是-scrapy-crawl-项目名"><a href="#71-Scrapy项目运行的命令是-scrapy-crawl-项目名" class="headerlink" title="71.Scrapy项目运行的命令是  scrapy  crawl   项目名"></a>71.Scrapy项目运行的命令是  scrapy  crawl   项目名</h3><h3 id="72-Scrapy框架创建爬虫文件的命令为-scrapy-genspider-爬虫名-www-baidu-com"><a href="#72-Scrapy框架创建爬虫文件的命令为-scrapy-genspider-爬虫名-www-baidu-com" class="headerlink" title="72.Scrapy框架创建爬虫文件的命令为  scrapy  genspider  爬虫名   www.baidu.com"></a>72.Scrapy框架创建爬虫文件的命令为  scrapy  genspider  爬虫名   <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a></h3><h3 id="73-简述-scrapy五大核心组件及作用"><a href="#73-简述-scrapy五大核心组件及作用" class="headerlink" title="73.简述 scrapy五大核心组件及作用"></a>73.简述 scrapy五大核心组件及作用</h3><p>​        (1) 引擎：负责各个组件之间的通讯信号及数据的传递 </p>
<p>​        (2) 爬虫：定义了爬取行为和解析规则，提交 item并传给管道</p>
<p>​        (3) 调度器：接受引擎传递的 request，并整理排列，然后进行请求的调 度 </p>
<p>​        (4) 下载器：负责下载 request，提交响应给引擎，引擎传递给 spider </p>
<p>​        (5) 管道:负责处理 spider传递来 的 item，如 去重、持久化存储等 </p>
<h3 id="74-Scrapy框架有哪些优点"><a href="#74-Scrapy框架有哪些优点" class="headerlink" title="74.Scrapy框架有哪些优点"></a>74.Scrapy框架有哪些优点</h3><p>​        (1) 框架封装的组件丰富，适用于开发大规模的抓取项目 </p>
<p>​        (2) 框架基于 Twisted异步框架，异步处理请求，更快捷，更高效 </p>
<p>​        (3) 拥有强大的社区支持，拥有丰富的插件来扩展其功能 </p>
<h3 id="75-Scrapy基于-Twisted异步-框架"><a href="#75-Scrapy基于-Twisted异步-框架" class="headerlink" title="75.Scrapy基于 Twisted异步 框架"></a>75.Scrapy基于 Twisted异步 框架</h3><h3 id="76-Allowed-domains的作用是-限制爬虫爬取的范围"><a href="#76-Allowed-domains的作用是-限制爬虫爬取的范围" class="headerlink" title="76.Allowed_domains的作用是 限制爬虫爬取的范围"></a>76.Allowed_domains的作用是 限制爬虫爬取的范围</h3><h3 id="77-请简述-scrapy框架五大核心组件有哪些"><a href="#77-请简述-scrapy框架五大核心组件有哪些" class="headerlink" title="77.请简述 scrapy框架五大核心组件有哪些"></a>77.请简述 scrapy框架五大核心组件有哪些</h3><p>​        (1) 引擎         (37) 爬虫         (2) 调度器         (3) 下载器         (4) 管道 </p>
<h3 id="78-如何判断-scrapy管道类是否需要-returnitem"><a href="#78-如何判断-scrapy管道类是否需要-returnitem" class="headerlink" title="78.如何判断 scrapy管道类是否需要 returnitem"></a>78.如何判断 scrapy管道类是否需要 returnitem</h3><p>​        (1) 在 scrapy框架中，可以自定义多个管道类，以满足不同的数据持久 化需求，当定义多管理类时，多个管道需传递         item来进行存储，管道类 各有自己的权重，权重越小，我们认为越接近引擎，越先接受引擎传递 来的 item 进行存        储， 故欲使权重大的管道能够接受到 item，前一个管 道必须 returnitem，如果一个管道类后无其他管道类，该管道        则无需 returnitem </p>
<h3 id="79-请问为什么下载器返回的相应数据不是直接通过引擎传递给管道，而是传递-给-spider"><a href="#79-请问为什么下载器返回的相应数据不是直接通过引擎传递给管道，而是传递-给-spider" class="headerlink" title="79.请问为什么下载器返回的相应数据不是直接通过引擎传递给管道，而是传递 给 spider"></a>79.请问为什么下载器返回的相应数据不是直接通过引擎传递给管道，而是传递 给 spider</h3><p>​        (1) 由于在 scrapy中，spider不但定义了爬取的行为，还定义了数据解 析规则，所以响应数据需传递给 spider进行数        据解析后，才能将目标数 据传递给管道，进行持久化存储 </p>
<h3 id="80-在-scrapy框架中手动发起请求时，使用-meta-参数给解析方法传递数据"><a href="#80-在-scrapy框架中手动发起请求时，使用-meta-参数给解析方法传递数据" class="headerlink" title="80.在 scrapy框架中手动发起请求时，使用 meta 参数给解析方法传递数据"></a>80.在 scrapy框架中手动发起请求时，使用 meta 参数给解析方法传递数据</h3><h3 id="81-Scrapy框架发送-post请求使用-FormRequest-方法"><a href="#81-Scrapy框架发送-post请求使用-FormRequest-方法" class="headerlink" title="81.Scrapy框架发送 post请求使用 FormRequest 方法"></a>81.Scrapy框架发送 post请求使用 FormRequest 方法</h3><h3 id="82-请简述scrapy阻止对start-urls内url主动发送请求时重写的父类方法名称，-及使用-scrapy-request的常用参数及含义"><a href="#82-请简述scrapy阻止对start-urls内url主动发送请求时重写的父类方法名称，-及使用-scrapy-request的常用参数及含义" class="headerlink" title="82.请简述scrapy阻止对start_urls内url主动发送请求时重写的父类方法名称， 及使用 scrapy.request的常用参数及含义"></a>82.请简述scrapy阻止对start_urls内url主动发送请求时重写的父类方法名称， 及使用 scrapy.request的常用参数及含义</h3><p>​        (1) 父类方法名称：start_requests </p>
<p>​        (2) 参数： ② Url——&gt;发送请求 ③ Callback—–&gt;指定回调，解析方法 </p>
<h3 id="83-简述详情页爬取的思路"><a href="#83-简述详情页爬取的思路" class="headerlink" title="83.简述详情页爬取的思路"></a>83.简述详情页爬取的思路</h3><p>​        (1) 访问列表页 </p>
<p>​        (2) 从列表页的响应数据中获取详情页 url </p>
<p>​        (3) 请求详情页 url，使用 scrapy.request手动发送请求并指定回调 </p>
<p>​        (4) 解析数据在回调中获取目标数据 84.简述多页爬取的思路 </p>
<p>​        (5) 思路一：将所有的页面 url生成后放在 start_urls中，当项目启动后 会对 start_urls中的 url发起请求，实现多页取 </p>
<p>​        (6) 思路二：在解析方法中构建 url，使用 scrapy手动发送请求并指定 回调，实现多页爬取 </p>
<h3 id="85-安装-scrapy框架的命令为-pipinstall-scrapy"><a href="#85-安装-scrapy框架的命令为-pipinstall-scrapy" class="headerlink" title="85.安装 scrapy框架的命令为 pipinstall  scrapy"></a>85.安装 scrapy框架的命令为 pipinstall  scrapy</h3><h3 id="86-Scrapy框架管道必须实现的方法是-process-item"><a href="#86-Scrapy框架管道必须实现的方法是-process-item" class="headerlink" title="86.Scrapy框架管道必须实现的方法是 process_item"></a>86.Scrapy框架管道必须实现的方法是 process_item</h3><h3 id="87-请使用-fake-useragent模块实现一个简单的-ua池"><a href="#87-请使用-fake-useragent模块实现一个简单的-ua池" class="headerlink" title="87.请使用 fake_useragent模块实现一个简单的 ua池"></a>87.请使用 fake_useragent模块实现一个简单的 ua池</h3><pre><code class="python">from fake_useragent import UserAgent 
Ua_obj=UserAgent() 
Ua_pool=[ ] 
for i in range(50): 
    Ua=ua_obj.chrome 
    Ua_pool.append(ua) 
from fake_useragent import UserAgent 
    ua=UserAgent() 
    ua_pool=[] 
    for i in range(50): 
        user_agent=ua.Chrome 
        ua_pool.append(user_agent) 
def process_request(self,request,spider):                 request.headers[&#39;UserAgent&#39;]=random.choice(ua_pool)     returnNone 
class UaSpider(scrapy.Spider): 
    name=&#39;ua&#39; 
    #allowed_domains=[&#39;baidu.com&#39;] 
    start_urls=[&#39;http://baidu.com/&#39;foriinrange(10)]     def parse(self,response): 
        pass </code></pre>
<h3 id="88-Scrapy框架中间件的分类及其作用"><a href="#88-Scrapy框架中间件的分类及其作用" class="headerlink" title="88.Scrapy框架中间件的分类及其作用"></a>88.Scrapy框架中间件的分类及其作用</h3><p>​        (1)下载中间件：拦截请求与响应，用于篡改响应 </p>
<p>​        (2)爬虫中间件：除下载中间件的作用以外，还可以实现 item丢弃 </p>
<h3 id="89-Scrapy框架下载中间件的核心方法及其作用"><a href="#89-Scrapy框架下载中间件的核心方法及其作用" class="headerlink" title="89.Scrapy框架下载中间件的核心方法及其作用"></a>89.Scrapy框架下载中间件的核心方法及其作用</h3><p>​        (1)Process_request:拦截非异常请求 </p>
<p>​        (2)Process_response:拦截所有响应 </p>
<p>​        (3)Process_exception:拦截异常请求 </p>
<h3 id="90-修改-scrapy项目的配置需要修改-settings-文件"><a href="#90-修改-scrapy项目的配置需要修改-settings-文件" class="headerlink" title="90.修改 scrapy项目的配置需要修改 settings 文件"></a>90.修改 scrapy项目的配置需要修改 settings 文件</h3><h3 id="91-应用-selenium框架实例化浏览器对象时，使用-executable-path-参数指-定驱动路径"><a href="#91-应用-selenium框架实例化浏览器对象时，使用-executable-path-参数指-定驱动路径" class="headerlink" title="91.应用 selenium框架实例化浏览器对象时，使用 executable_path 参数指 定驱动路径"></a>91.应用 selenium框架实例化浏览器对象时，使用 executable_path 参数指 定驱动路径</h3><h3 id="92-动态数据加载的两种情况及相应的解决方案"><a href="#92-动态数据加载的两种情况及相应的解决方案" class="headerlink" title="92.动态数据加载的两种情况及相应的解决方案"></a>92.动态数据加载的两种情况及相应的解决方案</h3><p>​        (1)ajax请求 ① 方案：如果 url有规律，直接构建 url实现请求，如果 url无规律， 则用 selenium </p>
<p>​        (2)Js动态数据加载 ① 方案：可以采用 scrapy框架与 selenium框架对接，实现动态数据 加载 </p>
<h3 id="93-简述-selenium与-scrapy框架对接实现动态加载数据的爬取思路"><a href="#93-简述-selenium与-scrapy框架对接实现动态加载数据的爬取思路" class="headerlink" title="93.简述 selenium与 scrapy框架对接实现动态加载数据的爬取思路"></a>93.简述 selenium与 scrapy框架对接实现动态加载数据的爬取思路</h3><p>​        (1)在 scrapy项目中正常对动态加载的页面发起请求，在下载中间件中拦截 动态加载页面的响应数据,在                                      process_response方法中，调用 selenium 抓取相应的 url，获取 html源码后再替换原有响应 </p>
<h3 id="94-请写出-selenium的常用节点交互操作（至少-5条）"><a href="#94-请写出-selenium的常用节点交互操作（至少-5条）" class="headerlink" title="94.请写出 selenium的常用节点交互操作（至少 5条）"></a>94.请写出 selenium的常用节点交互操作（至少 5条）</h3><p>​        (1)Clear（）：清空 (2)send_keys（）：输入 (3)Click（）：点击 (4)Quit（）：退出 (5)double_click（）：双击 </p>
<h3 id="95-创建基于-crawl的全站爬虫的命令"><a href="#95-创建基于-crawl的全站爬虫的命令" class="headerlink" title="95.创建基于 crawl的全站爬虫的命令"></a>95.创建基于 crawl的全站爬虫的命令</h3><p>​        (1)scrapy  startproject  projectname </p>
<p>​        scrapy  genspider -t  crawl  spidername  baidu.com </p>
<h3 id="96-简述-pipeline的核心方法及各方法实现什么功能"><a href="#96-简述-pipeline的核心方法及各方法实现什么功能" class="headerlink" title="96.简述 pipeline的核心方法及各方法实现什么功能"></a>96.简述 pipeline的核心方法及各方法实现什么功能</h3><p>​        (1)From_crauler:它是一个类方法，用@classmethod装饰，用于获取项目 的配置 </p>
<p>​        (2)Open_spider:在爬虫开启时被调用，可在其中连接数据库 </p>
<p>​        (3)process_item：在该方法中实现与数据库的交互，存储数据 </p>
<p>​        (4)close_spider：在爬虫关闭时调用，可在其中关闭数据库连接 </p>
<h3 id="97-Scrapy原生框架实现分布式要依赖哪个组件？该组件解决了什么问题"><a href="#97-Scrapy原生框架实现分布式要依赖哪个组件？该组件解决了什么问题" class="headerlink" title="97.Scrapy原生框架实现分布式要依赖哪个组件？该组件解决了什么问题"></a>97.Scrapy原生框架实现分布式要依赖哪个组件？该组件解决了什么问题</h3><p>​        (1)scrapy_redis组件 </p>
<p>​        (2)该组件为分布式提供了共享的管道和共享的调度器 </p>
<h3 id="98-列举三种常用的网络数据爬取的模块或框架"><a href="#98-列举三种常用的网络数据爬取的模块或框架" class="headerlink" title="98.列举三种常用的网络数据爬取的模块或框架"></a>98.列举三种常用的网络数据爬取的模块或框架</h3><p>​        (1)Requests         (2)Scrapy         (3)Urllib         (4)Aiohttp         (5)Pyspider </p>
<h3 id="99-请谈谈动态数据加载的爬取思路"><a href="#99-请谈谈动态数据加载的爬取思路" class="headerlink" title="99.请谈谈动态数据加载的爬取思路"></a>99.请谈谈动态数据加载的爬取思路</h3><p>​        (1)在 scrapy项目中正常对动态加载的页面发起请求，在下载中间件中拦截 动态加载页面的响应数据,在                        process_response方法中，调用 selenium 抓取相应的 url，获取 html源码后再替换原有响应 </p>
<h3 id="100-请列举-5种反爬机制及其对应的反反爬-策略"><a href="#100-请列举-5种反爬机制及其对应的反反爬-策略" class="headerlink" title="100.请列举 5种反爬机制及其对应的反反爬 策略"></a>100.请列举 5种反爬机制及其对应的反反爬 策略</h3><p>​        (1)Ua检测：ua伪装</p>
<p>​        (2)Robots协 议 ： requests模 块 无 须 理 会 ， settings配 置 中 将 ROBOTSTXT_OBEY改为 False </p>
<p>​        (3)动态数据加载：selenium抓取 </p>
<p>​        (4)图片懒加载：根据响应数据获取实际的 src属性值 </p>
<p>​        (5)Ip封禁：使用代理 ip </p>
<p>101.请详细阐述如何在下载中间件中篡改请求头信息，代理 ip </p>
<p>​        (1)在下载中间件的 process_request中加入如下代码:</p>
<pre><code class="python">reuqest.meta[&quot;proxy&quot;]=&quot;http://ip:port&quot; #实现代理 ip 

request.header[&quot;User-Agent&quot;]=&quot;&quot; #实现 ua伪装 </code></pre>
<h3 id="102-请写出爬虫-数据持久化-Python与-mongodb数据库的交互编码"><a href="#102-请写出爬虫-数据持久化-Python与-mongodb数据库的交互编码" class="headerlink" title="102.请写出爬虫 数据持久化 Python与 mongodb数据库的交互编码"></a>102.请写出爬虫 数据持久化 Python与 mongodb数据库的交互编码</h3><pre><code class="python">import pymongo 
class SpiderPipline(object): 
    Conn=pymongo.MongoClient() 
    Db=conn.xxx 
    Table=db.xx 
    def process_item(self,item,spider):
        Self.table.insert_one(dict(item)) 
        Returnitem </code></pre>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 dujunjie666@gmail.com </span>
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">赏</a>
</p>


<div class="article_copyright">
    <p><span class="copy-title">文章标题:</span>爬虫题库</p>
    <p><span class="copy-title">文章字数:</span><span class="post-count">5k</span></p>
    <p><span class="copy-title">本文作者:</span><a  title="Besos的博客">Besos的博客</a></p>
    <p><span class="copy-title">发布时间:</span>2020-01-09, 08:48:19</p>
    <p><span class="copy-title">最后更新:</span>2020-01-09, 09:57:12</p>
    <span class="copy-title">原始链接:</span><a class="post-url" href="/2020/01/09/%E7%88%AC%E8%99%AB%E9%A2%98%E5%BA%93/" title="爬虫题库">http://yoursite.com/2020/01/09/%E7%88%AC%E8%99%AB%E9%A2%98%E5%BA%93/</a>
    <p>
        <span class="copy-title">版权声明:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
    </p>
</div>



    <div id="comments"></div>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

<script type="text/javascript">
    $.getScript('/js/gitalk.js', function () {
        var gitalk = new Gitalk({
            clientID: '49b9fdb1b37f3db31e86',
            clientSecret: 'eac6662e34fa47837ba44f4c8059450bb01bdb1b',
            repo: 'blogtalk',
            owner: 'dujunjie-com',
            admin: ['dujunjie-com'],
            id: decodeURI(location.pathname),
            distractionFreeMode: 'true',
            language: 'zh-CN',
            perPage: parseInt('10',10)
        })
        gitalk.render('comments')
    })
</script>




    




    </div>
    <div class="copyright">
        <p class="footer-entry">©2016-2020 dujunjie-com</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full"><span class="min "></span></button>
<button class="post-toc-menu"><span class="post-toc-menu-icons"></span></button>
<div class="post-toc"><span class="post-toc-title">目录</span>
    <div class="post-toc-content">

    </div>
</div>
<a class="" id="rocket" ></a>

    </div>
</div>
<div class="acParent"></div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.0.1" ></script>

<script src="/js/script.js?v=1.0.1" ></script>
<script>
    var img_resize = 'default';
    /*作者、标签的自动补全*/
    $(function () {
        $('.search').AutoComplete({
            'data': ['#python','#文件','#爬虫','#命令','#PostgreSQL','#git','#hugo','#vue','#django','#docker',],
            'itemHeight': 20,
            'width': 418
        }).AutoComplete('show');
    })
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $(".post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        
        $('pre code').each(function(){
            var lines = $(this).text().split('\n').length - 1, widther='';
            if (lines>99) {
                widther = 'widther'
            }
            var $numbering = $('<ul/>').addClass('pre-numbering ' + widther).attr("unselectable","on");
            $(this).addClass('has-numbering ' + widther)
                    .parent()
                    .append($numbering);
            for(var i=1;i<=lines;i++){
                $numbering.append($('<li/>').text(i));
            }
        });
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<style>
    pre{
        position: relative;
        margin-bottom: 24px;
        border-radius: 10px;
        border: 1px solid #e2dede;
        background: #FFF;
        overflow: hidden;
    }
    code.has-numbering{
        margin-left: 30px;
    }
    code.has-numbering.widther{
        margin-left: 35px;
    }
    .pre-numbering{
        margin: 0px;
        position: absolute;
        top: 0;
        left: 0;
        width: 20px;
        padding: 0.5em 3px 0.7em 5px;
        border-right: 1px solid #C3CCD0;
        text-align: right;
        color: #AAA;
        background-color: #fafafa;
    }
    .pre-numbering.widther {
        width: 35px;
    }
</style>

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
        .nav .hide-list.fullscreen {
            left: 492px
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    
    .post .pjax article .article-entry>ol, .post .pjax article .article-entry>ul, .post .pjax article>ol, .post .pjax article>ul{
        border: #e2dede solid 1px;
        border-radius: 10px;
        padding: 10px 32px 10px 56px;
    }
    .post .pjax article .article-entry li>ol, .post .pjax article .article-entry li>ul,.post .pjax article li>ol, .post .pjax article li>ul{
        padding-top: 5px;
        padding-bottom: 5px;
    }
    .post .pjax article .article-entry>ol>li, .post .pjax article .article-entry>ul>li,.post .pjax article>ol>li, .post .pjax article>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    .post .pjax article .article-entry li>ol>li, .post .pjax article .article-entry li>ul>li,.post .pjax article li>ol>li, .post .pjax article li>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    
    .nav-right:before {
        content: ' ';
        display: block;
        position: absolute;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        opacity: 0.3;
        background: url("https://i.loli.net/2019/07/22/5d3521411f3f169375.png");
        background-repeat: no-repeat;
        background-position: 50% 0;
        -ms-background-size: cover;
        -o-background-size: cover;
        -moz-background-size: cover;
        -webkit-background-size: cover;
        background-size: cover;
    }
    

    
</style>






<div style="position:absolute; bottom: 0; right: 0;">
<embed src="//music.163.com/style/swf/widget.swf?sid=1401518640&type=2&auto=1&width=320&height=66" width="340" height="86"  allowNetworking="all"></embed>
</div>


</html>
